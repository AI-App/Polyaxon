---
version: 1

kind: experiment

logging:
  level: INFO
  path: /mypath/project1

environment:
  persistence:
    data: ['data1', 'data2']
    outputs: 'outputs1'

  resources:
    cpu:
      requests: 1
      limits: 2

  tensorflow:
    n_workers: 5
    n_ps: 10
    delay_workers_by_global_step: true

    run_config:
      tf_random_seed: 100
      save_summary_steps: 100
      save_checkpoints_secs: 60
      session:
        allow_soft_placement: true
        intra_op_parallelism_threads: 2
        inter_op_parallelism_threads: 2

    default_worker:
      config:
        allow_soft_placement: true
        intra_op_parallelism_threads: 1
        inter_op_parallelism_threads: 1

    worker:
      - index: 3
        config:
          allow_soft_placement: False
          intra_op_parallelism_threads: 5
          inter_op_parallelism_threads: 5
      - index: 4
        tolerations:
          - key: "key"
            operator: "Exists"
            effect: "NoSchedule"

    default_ps:
      resources:
        cpu:
          requests: 2
          limits: 4

    ps:
      - index: 7
        tolerations:
          - operator: "Exists"
        affinity:
          nodeAffinity:
            requiredDuringSchedulingIgnoredDuringExecution:
              nodeSelectorTerms:
              - matchExpressions:
                - key: kubernetes.io/e2e-az-name
                  operator: In
                  values:
                  - e2e-az1
                  - e2e-az2
            preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 1
              preference:
                matchExpressions:
                - key: another-node-label-key
                  operator: In
                  values:
                  - another-node-label-value
      - index: 9
        resources:
          memory:
            requests: 512
            limits: 1024


declarations:
  cnn:
    kernels: [64, 32]
    size: [2, 2]
    strides: [1, 1]

model:
  model_type: classifier
  loss: MeanSquaredError
  optimizer:
    Adam:
      learning_rate: 0.21
  graph:
    input_layers: images
    layers:
      - for:
          len: "{{ cnn.kernels|length }}"
          do:
            - Conv2D:
                filters: "{{ cnn.kernels[index] }}"
                kernel_size: "{{ cnn.size }}"
                strides: "{{ cnn.strides }}"
                activation: relu
                tags: tag1

      - if:
          cond: 1 == 1
          do:
            MaxPooling2D:
              kernels: 12

      - if:
          cond: "32 == {{ cnn.kernels[1] }}"
          do:
            for:
              len: "{{ cnn.kernels|length }}"
              do:
                - Conv2D:
                    filters: "{{ cnn.kernels[index] }}"
                    kernel_size: "{{ cnn.size }}"
                    strides: "{{ cnn.strides }}"
                    activation: relu
                    tags: tag2
                    is_output: true
          else_do:
            MaxPooling2D:
              kernels: 12
              is_output: true

      - Flatten:
          inbound_nodes: ["{{ tags.tag1[1] }}"]
      - Dense:
          units: 10
          activation: softmax
          name: super_dense
        
train:
  steps: 100
  data_pipeline:
    TFRecordImagePipeline:
      batch_size: 64
      num_epochs: 1
      shuffle: true
      dynamic_pad: false
      data_files: ["../data/mnist/mnist_train.tfrecord"]
      meta_data_file: "../data/mnist/meta_data.json"
      feature_processors:
        image:
          input_layers: [image]
          layers:
            - Cast:
                dtype: float32

eval:
  data_pipeline:
    TFRecordImagePipeline:
      batch_size: 32
      num_epochs: 1
      shuffle: False
      data_files: ["../data/mnist/mnist_train.tfrecord"]
      meta_data_file: "../data/mnist/meta_data.json"
...
